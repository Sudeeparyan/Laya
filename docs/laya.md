Architecting an Intelligent Medical Claims Adjudication System for Laya Healthcare: A Multi-Agent AI ApproachThe Strategic Imperative for Automation in the Irish Health Insurance MarketThe modernization of medical claims adjudication represents one of the most operationally complex challenges within the global healthcare sector. In the context of the Irish health insurance market, the necessity for robust, rapid, and highly accurate claims processing is amplified by intricate regulatory frameworks and escalating consumer expectations. Laya Healthcare, commanding a substantial 28% share of the Irish private health insurance market, stands as the second-largest open membership undertaking in the country. The organization has actively pursued front-end digital transformation, successfully launching a centralized digital hub that delivers over 500,000 general practitioner (GP) consultations and maintains a robust digital infrastructure with impressive Net Promoter Scores for its telehealth services.However, a stark operational dichotomy exists between this highly optimized front-end patient experience and the administrative backend responsible for financial adjudication. The backend processing of medical claims exhibits significant signs of systemic strain, primarily due to an over-reliance on manual review protocols. Medical claims teams at Laya Healthcare expend vast amounts of human capital manually verifying each incoming claim against complex policy documents, member history records, and uploaded supplementary files such as GP referrals. This manual adjudication is inherently slow, highly repetitive, susceptible to cognitive fatigue, and exceptionally difficult to audit retrospectively.An analysis of consumer sentiment and operational feedback reveals critical friction points resulting directly from these backend inefficiencies. Reviewers and policyholders frequently report that standard review times for claims have extended to 22 business days, representing a severe degradation from historical turnaround times where claims were processed in a matter of days. Policyholders express profound dissatisfaction over extended wait times for customer service, opaque decision-making regarding claim denials, and retroactive policy alterations that require extensive manual intervention to resolve. The public sentiment occasionally characterizes the customer service experience as deeply frustrating, with members reporting up to 40-minute wait times on phone lines to resolve simple claims inquiries.Furthermore, the Irish health insurance market operates under strict statutory guidelines, primarily the Risk Equalisation Scheme (RES), which is overseen by the Health Insurance Authority (HIA). Recent legislative amendments have introduced a High-Cost Claims Pool (HCCP), designed to distribute the financial burden of exceptionally expensive medical treatments across the market. This legislation provides a specific "high cost claim credit" equivalent to a 40% quota share for cumulative claim amounts that exceed a €50,000 threshold for a single member within a rolling 12-month period. Tracking this specific "claim quota" requires meticulous, error-free financial aggregation across multiple disparate claims for a single member over an extended temporal window. When claims arrive from multiple sources—such as emails from clinics, portal uploads from patients, and direct electronic data interchanges—consolidating these records manually to track the €50,000 quota threshold introduces an unacceptable level of operational risk and financial leakage.To resolve these systemic inefficiencies, reduce adjudication latency, and improve processing accuracy, a highly sophisticated Artificial Intelligence (AI) prototype is required. A monolithic Large Language Model (LLM) is technologically insufficient for this task, as monolithic models suffer from context degradation, increased hallucination rates when processing long instructional prompts, and an inability to reliably execute multi-step deterministic workflows. Therefore, the optimal architectural solution necessitates a Multi-Agent System (MAS), wherein specialized, narrowly defined AI agents handle specific components of the adjudication process under a strict hierarchical structure.Architectural Paradigm: The Google Agent Development Kit (ADK)The Google Agent Development Kit (ADK) provides the foundational framework for constructing this modular, scalable, and production-ready multi-agent system. The ADK embraces a decentralized, code-first philosophy, allowing developers to define discrete agent roles that operate collaboratively to execute complex business logic. By abstracting the complexities of underlying LLM interactions and tool invocations, the ADK permits the orchestration of highly specialized agents that function analogously to a human corporate hierarchy.The Strict Agent HierarchyWithin the ADK framework, the system is organized into a strict hierarchical tree structure. This hierarchy ensures a clear chain of command and predictable data flow, which is absolutely paramount for auditing financial and medical decisions in a regulated environment. The architecture is governed by a single-parent rule enforced by the ADK's BaseAgent class, dictating that an agent instance can only have one parent. This structural rigidity prevents infinite execution loops and ensures precise control over task delegation.For the Laya Healthcare prototype, the architecture is designed around a 1-3-6 hierarchical model:The Principal Agent (1): Acting as the central orchestrator and primary interface for incoming claims data.The Parent Agents (3): Specialized workflow managers that oversee distinct phases of the adjudication lifecycle.The Child Agents (6): Narrowly focused specialist agents, each assigned to answer one of six independent triage questions.Workflow Orchestration: Sequential and Parallel MethodologiesTo manage the execution flow without relying entirely on non-deterministic LLM routing, the ADK utilizes specialized Workflow Agents. These agents do not perform the reasoning tasks themselves; rather, they manage the execution sequence of their sub-agents.Workflow Agent TypeExecution MethodologyContext ManagementOptimal Claims Processing Use CaseSequential AgentExecutes sub-agents one after another in a strictly defined list.Passes the exact same InvocationContext sequentially, allowing agents to read/write to shared state keys.Financial calculation followed by response generation; Step B strictly requires the output of Step A.Parallel AgentExecutes all assigned sub-agents concurrently across multiple threads.Clones the InvocationContext for each sub-agent to prevent race conditions, then consolidates the results.Independent verification tasks, such as verifying member identity while simultaneously validating a GP referral document.The strategic application of these workflow patterns directly addresses the 22-day latency currently experienced by Laya Healthcare members. By executing independent verification tasks concurrently via ParallelAgent abstractions, the system compresses the overall processing time from days to mere seconds.Core Adjudication Logic: The Six-Question Triage FrameworkMedical triage and claims routing require a highly structured methodology to evaluate severity, validity, and financial exposure. Utilizing a proven six-question triage logic ensures that all critical dimensions of a claim are evaluated systematically, leaving no ambiguity in the final adjudication decision. The proposed architecture maps these six independent questions directly to the six Child agents, overseen by the three Parent orchestrators.Parent 1: Intake and Eligibility Verification (Parallel Workflow)The first Parent agent utilizes a ParallelAgent workflow to rapidly establish the baseline validity of the claim and the claimant. Because the identity of the member and the temporal constraints of the policy can be evaluated independently, concurrent execution is optimal.Child 1: The "Who" Agent (Identity and Policy Status): This agent is solely responsible for answering, "Who is involved, and what is their status?". Its parameters dictate that it must verify the provided member ID against the Azure database, confirm that the specific health insurance policy (e.g., "Advantage 125 Explore" or "Essential Plus") was active on the exact date of service, and verify the identities of any dependents listed on the claim.Child 2: The "When" Agent (Temporal Exclusions and Deadlines): Operating concurrently, this agent answers, "When did the incident occur, and are there temporal exclusions?". It checks the Laya Healthcare rulebook for standard waiting periods, pre-existing condition exclusions, and ensures that the claim was submitted within the mandatory twelve-month timeframe from the end of the policy year, as dictated by Laya's claim submission guidelines.Parent 2: Clinical Assessment and Fraud Detection (Parallel Workflow)Once basic eligibility is confirmed, the Principal agent transfers the session state to the second Parent agent, which evaluates the medical necessity and procedural validity of the claim. This also operates as a ParallelAgent to optimize speed.Child 3: The "Why" and "What" Agent (Clinical Validator): This agent answers, "What exactly happened, and why was it medically necessary?". It is tasked with reading uploaded clinical documents, specifically GP referrals. For instance, if a claim involves a consultant visit or a specific diagnostic imaging procedure (such as an MRI or CT scan), this agent utilizes optical character recognition (OCR) and text extraction to verify that the GP referral is present, valid, and matches the submitted ICD-10 or CPT procedure codes.Child 4: The "Where" and "How" Agent (Fraud and Anomaly Detector): This agent answers, "Where did the treatment occur, and how was it billed?". It verifies that the treatment facility is listed on Laya's approved hospital or diagnostic center network. Crucially, it employs pattern recognition to identify anomalies indicative of fraud or duplicate billing. It cross-references the database to ensure the exact procedure, performed on the exact date, by the exact provider, has not already been submitted or paid.Parent 3: Financial Resolution and Communication (Sequential Workflow)The final Parent agent operates as a SequentialAgent. In this phase, operations are strictly linear; financial calculations must be completed and audited before any customer communication can be generated.Child 5: The Financial Liability and Quota Agent: This agent synthesizes the outputs from the previous agents to calculate the exact financial payout. It applies the specific percentage limits of the member's plan. For example, if the member holds the "Principle" plan, it calculates a 75% reimbursement up to €50 per visit for physiotherapy. Furthermore, it strictly monitors the HIA High-Cost Claim Quota. It queries the database to sum the member's total claims over the rolling 12-month period. If the cumulative total exceeds €50,000, it calculates the 40% quota share credit and flags the record for internal regulatory reporting to the Health Insurance Authority.Child 6: The Resolution and Pre-defined Response Agent: Acting as the final node in the sequential pipeline, this agent accesses a centralized repository originating from an Excel matrix of pre-defined, legally compliant responses. Based on the adjudication outcome (approved, denied, partially paid, or pending further information), it selects the perfectly matched explanation code, formats a detailed Explanation of Benefits (EOB), and generates a chatbot text summary or an email draft. This ensures that all member communication is highly standardized, easily auditable, and instantly available, directly resolving the customer pain point of opaque communication.Data Consolidation and Persistent State ManagementA critical vulnerability in legacy claims systems is the handling of multi-channel ingestion. A member might upload a receipt via the Laya App, while the treating clinic simultaneously emails the same invoice directly to the claims department. The business logic dictates that multiple claim submissions originating from multiple sources must be consolidated, and only one definitive record must be saved, indexed by the combination of Member ID and Claim Number.Email Ingestion and Database IdempotencyTo achieve this, the architecture requires a robust data ingestion pipeline connected to an Azure Database for MySQL Flexible Server. When emails containing claim information are received, a pre-processing script parses the text and attachments, extracting the core entities.The database schema is strictly designed with a unique composite primary key combining the Member_ID and the Claim_Number. When the AI system attempts to write a new claim record to the database, it utilizes the MySQL-specific INSERT... ON DUPLICATE KEY UPDATE statement. This command guarantees idempotency at the database level. If the primary key does not exist, a new row is inserted. If the key already exists (because the claim was already submitted via another channel), the database automatically performs an update operation instead of throwing a fatal duplicate key exception. This architectural choice prevents database crashes during high-concurrency periods and ensures that the AI agents can safely update claim statuses (e.g., moving a claim from "Pending" to "Approved") without artificially inflating the member's claim history or disrupting the €50,000 claim quota calculations.Integrating an Azure MySQL database with autonomous AI agents requires strict adherence to enterprise security best practices. All connections must be encrypted using Transport Layer Security (TLS 1.2 minimum) via Azure virtual networks to ensure private communication, thereby protecting sensitive Protected Health Information (PHI). Connection pooling must be utilized to manage the high volume of parallel requests generated by the multi-agent system, preventing intermittent connection failures and storage bottlenecks.Persistent Session Management in ADKWithin the ADK framework, maintaining the context of a complex claim as it traverses the six-agent hierarchy requires sophisticated persistent state management. A stateless AI suffers from "digital amnesia," meaning it loses all context between interactions, which is catastrophic in financial adjudication.The ADK framework resolves this via the DatabaseSessionService, which handles all complexities of state serialization, storage, and retrieval. State is organized using specific prefixes to define scope and memory length :State PrefixScope and PersistenceApplication in Claims Adjudicationtemp:Temporary Invocation State; exists only during a single processing turn.Used by the SequentialAgent to pass extracted ICD-10 codes from Child 3 directly to Child 4 for immediate fraud checking.session:Tied to the specific interaction instance.Tracks the specific lifecycle of the current claim. If the system pauses to request a missing GP referral, it resumes exactly where it left off when the document is provided.user:Tied to the specific user_id; persists across multiple independent sessions.Allows the system to remember past interactions, historical claim totals, and cumulative quota amounts across the member's entire policy year.By binding the ADK's DatabaseSessionService directly to the Azure MySQL backend, the system achieves true persistence, maintaining an immutable event log of every tool request, agent reply, and state change for flawless retrospective auditability.Standardized Integration Protocols: MCP and A2AFor the multi-agent system to function effectively within Laya Healthcare's broader enterprise architecture, it must interact securely with external databases, static Excel files, and legacy systems. The architecture achieves this through a dual-protocol approach, utilizing Anthropic's Model Context Protocol (MCP) for vertical integration and Google's Agent-to-Agent (A2A) protocol for horizontal collaboration.Model Context Protocol (MCP) for Vertical Tool IntegrationIntroduced as an open-source standard, MCP serves as a universal interface layer—often described as a "USB-C port for AI"—that connects AI models to external tools, databases, and APIs without requiring custom, brittle integrations for every distinct data source.Within the Laya Healthcare prototype, MCP handles the vertical integration required by the agents to perform their duties. When Child 1 needs to verify member eligibility, or Child 5 needs to retrieve current financial limits, they do not rely on hallucinated or pre-trained data; instead, they utilize an MCP server securely connected to the Azure MySQL database. The ADK's McpToolset class allows developers to instantiate MCP directly within the tools list of an LlmAgent. This standardizes exactly how agents pull member records, retrieve GP referral PDFs from secure cloud storage, and execute read/write queries to the database.For this specific implementation, an MCP server specifically built for Azure Database for MySQL provides tools that allow the agent to execute read queries, list available tables, and securely insert new claims data. Furthermore, an additional MCP integration allows Child 6 to dynamically query the static Excel file containing the predefined chat summaries and email responses, ensuring that the AI only outputs organizationally approved language.Agent-to-Agent (A2A) Protocol for Horizontal CollaborationWhile MCP standardizes agent-to-tool communication, the A2A protocol standardizes agent-to-agent communication. Developed by Google and supported by major enterprise software vendors, A2A allows distinct AI agents—even those built on entirely different frameworks like LangChain, CrewAI, or bespoke legacy systems—to discover each other, negotiate, and collaborate on complex workflows.In a complex enterprise environment like Laya Healthcare, the Principal agent built on ADK may need to collaborate with a legacy rules-engine agent maintained by the underwriting department, or an external fraud-detection agent maintained by a third-party vendor. A2A uses JSON-RPC 2.0 over HTTP(S) to facilitate this rich data exchange. It allows the agents to exchange structured task requests and results without needing to share their internal memory structures, proprietary prompts, or specific tool implementations, thereby preserving strict security boundaries and architectural opacity.This hybrid utilization—where MCP fetches the structured data and A2A routes the intelligence horizontally across the organization—creates an exceptionally scalable and robust ecosystem. As noted in architectural analyses, "A2A is the API for agents, and MCP is the API for tools".Advanced Knowledge Integration: GraphRAG for Contextual ReasoningTo evaluate claims accurately, the AI must understand highly complex relationships between entities. Standard Retrieval-Augmented Generation (RAG) systems rely on vector databases that perform semantic similarity searches using cosine distance. While standard RAG is highly effective for retrieving isolated text fragments, it severely struggles with "context fragmentation"—situations where relevant information is spread across multiple policy documents, member histories, and clinical guidelines. Standard RAG cannot natively execute the multi-hop reasoning required to determine if a specific GP referral validates a specific consultant visit under the unique exclusions of a specific policy variant.The Mechanics of Graph-Based RetrievalGraph Retrieval-Augmented Generation (GraphRAG) resolves this fragmentation by explicitly modeling enterprise data as a relation-driven, dynamic knowledge graph. Using robust graph databases such as Neo4j or Memgraph, the system extracts entities and the explicit relationships between them to construct a structured mathematical network.In the Laya Healthcare architecture, the knowledge graph schema consists of defined nodes (e.g., Member, Policy, Claim, Procedure, Provider, GP) and edges representing semantic relationships (COVERED_BY, REFERRED_BY, PERFORMED_AT, HAS_EXCLUSION).When Child 3 (the Clinical Validator) receives a claim for analysis, it queries the GraphRAG system. The system performs a deterministic graph traversal rather than a probabilistic keyword search. For example, the query can follow a definitive path: Member A -> COVERED_BY -> Care Select Plan -> HAS_BENEFIT -> Radiology Diagnostic Test -> SUBJECT_TO -> 50% of costs in approved centers. This explicit traversal ensures that the AI applies the exact mathematical rules of the "Care Select" plan, rather than accidentally hallucinating the 75% reimbursement rate associated with the "Principle" plan.Community Detection for Advanced Fraud IdentificationBeyond simple policy lookups, GraphRAG employs sophisticated hierarchical community detection algorithms, such as the Leiden technique, to identify dense clusters of connected nodes within the graph. In the context of medical claims adjudication, this capability is profoundly powerful for identifying organized fraud.If a specific cluster of seemingly unrelated members is repeatedly referred by the same single GP to the same out-of-network provider for high-cost diagnostics, traditional RAG systems would fail to notice the pattern, as they evaluate claims in isolation. However, graph algorithms can identify this anomalous community pattern instantly, automatically flagging the entire cluster for manual investigation by the Special Investigations Unit (SIU). By grounding the LLM's responses in explicit graph paths rather than probabilistic vector distances, GraphRAG dramatically reduces hallucinations, providing transparent, traceable, and highly accurate reasoning for every single claim approval or denial.Latency Optimization: Cache-Augmented Generation (CAG)While GraphRAG provides unparalleled accuracy and deterministic reasoning, graph traversals and subsequent LLM generation can introduce computational latency. In a high-volume claims environment, where thousands of queries are processed daily, speed is a critical metric. To optimize the system's responsiveness and reduce operational costs, the architecture implements Cache-Augmented Generation (CAG).The Computational Differences: RAG vs. CAGThe distinction between RAG and CAG lies fundamentally in how contextual data is processed by the language model's underlying architecture:Retrieval-Augmented Generation (RAG) retrieves dynamic data in real-time and injects it directly into the prompt. This forces the LLM to process the entire context window from scratch for every single query. This process is highly computationally expensive, slow, and consumes vast amounts of tokens, driving up API costs.Cache-Augmented Generation (CAG) pre-computes and stores the Key-Value (KV) cache of the model's internal states for a specific, static corpus of text (often referred to as past_key_values in model architecture). When a new query is made, the model reuses this pre-processed memory, only needing to compute the logits for the new query tokens.Architectural FeatureRetrieval-Augmented Generation (RAG)Cache-Augmented Generation (CAG)Data Freshness and MutabilityHigh (Real-time dynamic retrieval of constantly changing data)Moderate (Relies on pre-loaded, static context windows)Processing Speed and LatencySlower (Computes full context embeddings per query)Extremely Fast (Reuses pre-computed KV cache)Computational Resource CostHigh (Token-intensive and high inference hardware load)Low (Demonstrates up to 76% token reduction usage) Optimal Adjudication Use CaseLive claim histories, dynamic patient data, daily fluctuating quota totals.Static policy documents, standardized Excel response matrices.Strategic Implementation of CAG in the Development EnvironmentDuring the prototyping phase, the implementation and testing of the CAG system can be executed seamlessly within a VS Code environment, utilizing open-source models to validate the token reduction metrics.In the production architecture for Laya Healthcare, CAG is strategically utilized for the static components of the system. Health insurance policy documents, such as the 100-page 2025 Standard Policy terms and specific benefit tables, change infrequently (typically once per annual renewal cycle). Similarly, the target architecture relies on an Excel database holding all pre-defined operational responses, legal disclaimers, and compliance explanations.Instead of retrieving these massive documents via RAG for every single claim, the system ingests the policy manuals and the Excel response matrix at system startup, processes them through the LLM once, and saves the resulting KV cache to a local or distributed cache. When Child 6 (the Resolution Agent) is tasked with drafting the final response, it references this preloaded cache. This approach eliminates the need for repeated document retrieval and redundant token processing, yielding massive reductions in token usage and generating compliant, context-aware responses almost instantaneously.By deploying a hybrid knowledge architecture—utilizing GraphRAG for dynamic, relationship-based claim verification and fraud detection, while utilizing CAG for rapid static policy lookups and response generation—the architecture achieves a perfect equilibrium between rigorous analytical accuracy and unprecedented operational velocity.ConclusionThe integration of advanced Artificial Intelligence into Laya Healthcare's medical claims infrastructure offers a definitive, architecturally sound solution to the persistent operational challenges of processing latency, manual review bottlenecks, and retrospective audit complexity. By moving beyond rudimentary chatbots and monolithic models to implement a highly structured Multi-Agent System via the Google Agent Development Kit, the architecture mirrors the sophisticated, multi-disciplinary nature of human claims adjudication teams while operating at machine speed.The strict hierarchical orchestration of Principal, Parent, and Child agents ensures that the six fundamental questions of medical claims triage are executed deterministically and concurrently. The integration of the Model Context Protocol and the Agent-to-Agent protocol guarantees secure, scalable interoperability with both internal legacy databases and external analytical tools. Furthermore, the strategic application of an Azure MySQL backend, utilizing idempotent update operations and persistent session management, guarantees absolute data integrity and precise, real-time tracking of critical financial metrics, such as the mandated high-cost claim quota.Finally, the synthesized deployment of Graph Retrieval-Augmented Generation and Cache-Augmented Generation provides the system with the deep contextual reasoning required for complex medical evaluation and the low-latency performance necessary for enterprise-scale deployment. This paradigm not only drastically reduces the time and operational costs associated with manual claims checking, but it also establishes a highly transparent, inherently explainable technological framework that is perfectly suited for the rigorous regulatory and consumer environment of the modern Irish health insurance market.