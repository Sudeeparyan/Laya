"""
Laya Healthcare — Claims Router
GET /api/claims/{member_id} — Get claims history
POST /api/upload — Upload document for OCR processing
"""

from __future__ import annotations

import base64
import re
import zlib
from datetime import datetime, timezone

from fastapi import APIRouter, HTTPException, UploadFile, File, Request
from fastapi.responses import FileResponse

from app.models.database import get_claims_history, add_uploaded_document, add_activity
from app.tools.ocr_tools import mock_ocr_extract, real_ocr_extract
from app.config import settings
from app.auth.users import decode_token, get_user_by_id

router = APIRouter()


@router.get("/files/{doc_id}")
async def serve_file(doc_id: str):
    """Serve a previously uploaded file by its document ID for preview."""
    import os, glob
    uploads_dir = settings.UPLOADS_DIR
    # Find files matching the doc_id prefix
    matches = glob.glob(os.path.join(uploads_dir, f"{doc_id}.*"))
    if not matches:
        raise HTTPException(status_code=404, detail=f"File {doc_id} not found")

    file_path = matches[0]
    filename = os.path.basename(file_path)
    ext = os.path.splitext(filename)[1].lower()

    media_types = {
        ".pdf": "application/pdf",
        ".png": "image/png",
        ".jpg": "image/jpeg",
        ".jpeg": "image/jpeg",
    }

    return FileResponse(
        path=file_path,
        media_type=media_types.get(ext, "application/octet-stream"),
        filename=filename,
        headers={"Content-Disposition": "inline"},
    )

@router.get("/claims/{member_id}")
async def get_member_claims(member_id: str):
    """Return claims history for a specific member."""
    history = get_claims_history(member_id)
    return {"member_id": member_id, "claims": history, "total": len(history)}


def _extract_text_from_pdf(pdf_bytes: bytes) -> str:
    """Extract text content from a PDF file.
    Handles both compressed (FlateDecode/zlib) and uncompressed streams.
    Works for text-based PDFs generated by fpdf2."""
    text_parts = []
    try:
        # Work directly with raw bytes for stream extraction to avoid encoding issues
        stream_pattern = re.compile(rb'stream\r?\n(.*?)endstream', re.DOTALL)
        decompressed_blocks = []

        for match in stream_pattern.finditer(pdf_bytes):
            raw_bytes = match.group(1)
            # Try zlib decompression
            try:
                decompressed = zlib.decompress(raw_bytes)
                decompressed_blocks.append(decompressed.decode("latin-1", errors="ignore"))
            except zlib.error:
                # Not compressed, use raw decoded as latin-1
                decompressed_blocks.append(raw_bytes.decode("latin-1", errors="ignore"))

        # Also include the raw PDF content for uncompressed text
        content = pdf_bytes.decode("latin-1", errors="ignore")

        # Now extract text from all blocks (both decompressed and raw)
        all_content = "\n".join(decompressed_blocks) + "\n" + content

        # Find text between BT (Begin Text) and ET (End Text) markers
        bt_et_blocks = re.findall(r'BT\s(.*?)ET', all_content, re.DOTALL)
        for block in bt_et_blocks:
            # Extract text from Tj operators: (text) Tj
            tj_matches = re.findall(r'\((.*?)\)\s*Tj', block)
            text_parts.extend(tj_matches)
            # TJ arrays: [(text) num (text) ...] TJ
            tj_array_matches = re.findall(r'\[(.*?)\]\s*TJ', block)
            for arr in tj_array_matches:
                segments = re.findall(r'\((.*?)\)', arr)
                text_parts.extend(segments)

    except Exception:
        pass

    return " ".join(text_parts)


def _parse_claim_fields_from_text(text: str) -> dict:
    """Parse structured claim fields from extracted PDF text."""
    fields = {}

    # Member ID: MEM-XXXX
    mid = re.search(r'(MEM-\d{4})', text)
    if mid:
        fields["member_id"] = mid.group(1)

    # Patient Name — look for text after "Patient Name" label
    name_match = re.search(r'Patient\s+Name\s*:?\s*([A-Z][a-z]+(?:\s+O\')?[A-Z]?[a-z]*(?:\s+[A-Z][a-z]+)?)', text)
    if name_match:
        raw_name = name_match.group(1).strip()
        # Remove trailing words that aren't part of the name (like "Date")
        raw_name = re.sub(r'\s+(Date|of|Birth|Address|Eircode|Scheme).*$', '', raw_name)
        fields["patient_name"] = raw_name

    # Treatment Type — look for known treatment types
    treatment_types = [
        "GP & A&E", "Consultant Fee", "Prescription", "Day to Day Therapy",
        "Dental & Optical", "Scan Cover", "Hospital In-patient",
        "Maternity / Adoption Cash Back",
    ]
    for tt in treatment_types:
        if tt.lower() in text.lower() or tt in text:
            fields["treatment_type"] = tt
            break

    # Treatment Date: YYYY-MM-DD — prefer dates near "Treatment Date" label
    # First try to find date explicitly after "Treatment Date" label
    td_match = re.search(r'Treatment\s+Date\s*:?\s*(\d{4}-\d{2}-\d{2})', text)
    if td_match:
        fields["treatment_date"] = td_match.group(1)
    else:
        # Fall back to finding dates in 2025-2027 range (treatment dates, not DOBs)
        all_dates = re.findall(r'(202[5-7]-\d{2}-\d{2})', text)
        if all_dates:
            fields["treatment_date"] = all_dates[0]
        else:
            # Last resort: find any date, but prefer the second one (first is usually DOB)
            all_dates = re.findall(r'(\d{4}-\d{2}-\d{2})', text)
            if len(all_dates) >= 2:
                fields["treatment_date"] = all_dates[1]  # Second date is typically treatment
            elif all_dates:
                fields["treatment_date"] = all_dates[0]

    # Practitioner/Provider name — look for "Dr. XXX" or known hospital names
    _label_words = {"Practitioner", "Provider", "Address", "Date", "of",
                    "Birth", "Eircode", "Scheme", "Procedure", "Clinical"}

    def _clean_practitioner(name: str) -> str:
        parts = name.split()
        cleaned = []
        for p in parts:
            if p in _label_words:
                break
            cleaned.append(p)
        return " ".join(cleaned) if cleaned else name

    # Try to find after "Practitioner" label
    prac_match = re.search(r'(?:Practitioner|Provider)\s*(?:/\s*Provider)?\s*:?\s*(Dr\.?\s+[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)', text)
    if prac_match:
        fields["practitioner_name"] = _clean_practitioner(prac_match.group(1).strip())
    else:
        dr_match = re.search(r'(Dr\.?\s+[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)', text)
        if dr_match:
            fields["practitioner_name"] = _clean_practitioner(dr_match.group(1).strip())
        else:
            # Try hospital/clinic names
            hosp_match = re.search(r'((?:St\.?\s+)?[A-Z][a-z]+(?:\'s)?\s+(?:University\s+)?Hospital|Beacon\s+Hospital|[A-Z][a-z]+\s+Clinic)', text)
            if hosp_match:
                fields["practitioner_name"] = hosp_match.group(1)

    # Total Cost: EUR XX.XX
    cost_match = re.search(r'EUR\s+(\d+\.?\d*)', text)
    if cost_match:
        try:
            fields["total_cost"] = float(cost_match.group(1))
        except ValueError:
            pass

    # Form Type
    if "Pre and Post-Natal" in text:
        fields["form_type"] = "Pre and Post-Natal Claim Form"
    elif "Money Smart Out-patient" in text or "Out-patient" in text:
        fields["form_type"] = "Money Smart Out-patient Claim Form"
    elif "General Practitioner Claim" in text:
        fields["form_type"] = "General Practitioner Claim Form"

    # Signature
    if "[X]" in text and "Yes" in text:
        fields["signature_present"] = True
    # Check for signed name (italicized signature)
    if any(name in text for name in ["Liam", "Siobhan", "Declan", "Conor", "Aoife", "Niamh", "Sean"]):
        fields["signature_present"] = True

    # Hospital days
    days_match = re.search(r'Number\s+of\s+Days\s*:?\s*(\d+)', text)
    if days_match:
        fields["hospital_days"] = int(days_match.group(1))

    # Accident / Solicitor flags
    if "accident" in text.lower() or "injury" in text.lower():
        if "[x]" in text.lower():
            fields["is_accident"] = True
    if "solicitor" in text.lower() or "piab" in text.lower():
        if "[x]" in text.lower():
            fields["solicitor_involved"] = True

    return fields


@router.post("/upload")
async def upload_document(request: Request, file: UploadFile = File(...)):
    """Upload a claim document for OCR processing.

    In mock mode (default), extracts text from the PDF and parses claim fields.
    In real mode (USE_REAL_OCR=true), processes the image via GPT-4V.
    Also tracks the upload for developer visibility.
    """
    try:
        contents = await file.read()

        # Extract user context from JWT for tracking
        uploader_info = {}
        auth_header = request.headers.get("Authorization", "")
        if auth_header.startswith("Bearer "):
            token = auth_header.split(" ", 1)[1]
            payload = decode_token(token)
            if payload:
                user = get_user_by_id(payload["sub"])
                if user:
                    uploader_info = {
                        "uploaded_by": f"{user.get('first_name', '')} {user.get('last_name', '')}".strip(),
                        "uploaded_by_email": user.get("email", ""),
                        "uploaded_by_role": user.get("role", "customer"),
                        "linked_member_id": user.get("member_id"),
                    }

        if settings.USE_REAL_OCR:
            # Real OCR via GPT-4V
            image_b64 = base64.b64encode(contents).decode("utf-8")
            result = real_ocr_extract.invoke({"image_base64": image_b64})
        else:
            # Try to extract text from PDF and parse fields
            extracted_fields = {}
            if file.filename and file.filename.lower().endswith(".pdf"):
                pdf_text = _extract_text_from_pdf(contents)
                if pdf_text.strip():
                    extracted_fields = _parse_claim_fields_from_text(pdf_text)

            # Build result with extracted or template data
            extracted_data = {
                "member_id": extracted_fields.get("member_id", ""),
                "patient_name": extracted_fields.get("patient_name", ""),
                "form_type": extracted_fields.get("form_type", "Money Smart Out-patient Claim Form"),
                "treatment_type": extracted_fields.get("treatment_type", ""),
                "treatment_date": extracted_fields.get("treatment_date", ""),
                "practitioner_name": extracted_fields.get("practitioner_name", ""),
                "total_cost": extracted_fields.get("total_cost", 0.0),
                "signature_present": extracted_fields.get("signature_present", True),
            }

            # Include optional fields if found
            if "hospital_days" in extracted_fields:
                extracted_data["hospital_days"] = extracted_fields["hospital_days"]
            if "is_accident" in extracted_fields:
                extracted_data["is_accident"] = extracted_fields["is_accident"]
            if "solicitor_involved" in extracted_fields:
                extracted_data["solicitor_involved"] = extracted_fields["solicitor_involved"]

            has_content = bool(extracted_fields.get("treatment_type") or extracted_fields.get("member_id"))
            result = {
                "success": True,
                "extraction_method": "pdf_text_extraction" if has_content else "mock_template",
                "message": (
                    f"Document parsed successfully. Extracted: {extracted_fields.get('treatment_type', 'N/A')} "
                    f"for {extracted_fields.get('patient_name', 'member')}."
                    if has_content
                    else "Document received but could not extract structured data. "
                         "The AI will infer claim details from your message."
                ),
                "extracted_data": extracted_data,
            }

        # Track the document upload for developer visibility
        member_id = result.get("extracted_data", {}).get("member_id", "") or uploader_info.get("linked_member_id", "")
        doc_id = f"DOC-{datetime.now(timezone.utc).strftime('%Y%m%d%H%M%S')}"

        # Save the actual file to disk for preview
        import os
        uploads_dir = settings.UPLOADS_DIR
        os.makedirs(uploads_dir, exist_ok=True)
        file_ext = os.path.splitext(file.filename or "file")[1] or ".pdf"
        saved_filename = f"{doc_id}{file_ext}"
        saved_path = os.path.join(uploads_dir, saved_filename)
        with open(saved_path, "wb") as f:
            f.write(contents)

        file_url = f"/api/files/{doc_id}"

        if member_id:
            doc_record = {
                "doc_id": doc_id,
                "filename": file.filename or "unknown",
                "saved_filename": saved_filename,
                "file_url": file_url,
                "uploaded_at": datetime.now(timezone.utc).isoformat(),
                "extraction_method": result.get("extraction_method", "unknown"),
                "extracted_data": result.get("extracted_data", {}),
                **uploader_info,
            }
            add_uploaded_document(member_id, doc_record)

            # Track activity for developer monitoring
            add_activity({
                "type": "file_upload",
                "member_id": member_id,
                "user_name": uploader_info.get("uploaded_by", "Unknown"),
                "user_role": uploader_info.get("uploaded_by_role", "customer"),
                "description": f"Uploaded document: {file.filename or 'unknown'}",
                "details": {
                    "doc_id": doc_id,
                    "filename": file.filename,
                    "file_url": file_url,
                    "treatment_type": result.get("extracted_data", {}).get("treatment_type", ""),
                    "total_cost": result.get("extracted_data", {}).get("total_cost", 0),
                    "extraction_method": result.get("extraction_method", "unknown"),
                },
            })

        # Include file_url in the response so frontend can preview
        result["file_url"] = file_url
        result["doc_id"] = doc_id

        return result

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Error processing upload: {str(e)}",
        )
